{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most harmless user function of Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1: \n",
      "    A  B\n",
      "0  1  1\n",
      "1  2  2\n",
      "2  3  6 \n",
      "\n",
      "df1: \n",
      "    B   C\n",
      "0  1  10\n",
      "1  2  11\n",
      "2  9  12 \n",
      "\n",
      "df1: \n",
      "     C   D\n",
      "0  10  16\n",
      "1   3  17\n",
      "2  15  18 \n",
      "\n",
      "merged df: \n",
      "      A    B   C     D\n",
      "0  1.0  1.0  10  16.0\n",
      "1  2.0  2.0  11   NaN\n",
      "2  NaN  NaN   3  17.0\n",
      "3  NaN  NaN  15  18.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "def merge_df_list(df_left: pd.DataFrame, dfs_right: List[pd.DataFrame], keys: List[str], methods: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    功能：横向合并多个df\n",
    "    参数：\n",
    "    df_left: 最左边的df\n",
    "    df_list：需要合并的df列表(除最左边的以外)\n",
    "    keys：合并df所需要的key列表，需要与df_list一一对应, 列表元素为一个二元元组，元组元素为str列表\n",
    "    methods: 合并df所需要的方法列表，需要与df_list一一对应\n",
    "\n",
    "    返回值：合并后的df\n",
    "    \"\"\"\n",
    "    # 将最左边的数据帧赋值给df_merged\n",
    "    df_merged = df_left\n",
    "    # 使用zip函数同时迭代df_right，keys和methods列表\n",
    "    for df, key, method in zip(dfs_right, keys, methods):\n",
    "        # 使用指定的键和方法合并当前数据帧与df_merged\n",
    "        df_merged = df_merged.merge(df, left_on=key[0], right_on=key[1], how=method)\n",
    "    # 返回合并后的数据帧\n",
    "    return df_merged\n",
    "\n",
    "# 示例代码：\n",
    "if __name__ == \"__main__\":\n",
    "    df1 = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [1, 2, 6]})\n",
    "    df2 = pd.DataFrame({\"B\": [1, 2, 9], \"C\": [10, 11, 12]})\n",
    "    df3 = pd.DataFrame({\"C\": [10, 3, 15], \"D\": [16, 17, 18]})\n",
    "\n",
    "\n",
    "    df_left = df1\n",
    "    df_right = [df2, df3]\n",
    "    keys = [(\"B\",\"B\"),(\"C\",\"C\")]\n",
    "    methods = ['inner','outer']\n",
    "\n",
    "    merged_df = merge_df_list(df_left,df_right, keys,methods)\n",
    "    print(f\"df1: \\n {df1} \\n\")\n",
    "    print(f\"df1: \\n {df2} \\n\")\n",
    "    print(f\"df1: \\n {df3} \\n\")\n",
    "    print(f\"merged df: \\n {merged_df} \\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量扫描文件夹并获取文件路径\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未排除csv文件的路径如下: \n",
      " ./assets/auto.dta \n",
      "\n",
      "未排除csv文件的路径如下: \n",
      " ./assets/auto.csv \n",
      "\n",
      "排除csv文件的路径如下: \n",
      " ./assets/auto.dta \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from typing import List, Generator\n",
    "\n",
    "def scan_file_path(\n",
    "    folder: str, \n",
    "    extensions: List[str], \n",
    "    exclude: str=\"^$\", \n",
    "    recursive: bool=False) -> Generator[str, None, None]:\n",
    "    \"\"\"生成器函数，用于生成符合指定条件的文件路径。\n",
    "\n",
    "    Args:\n",
    "        folder (str): 要扫描的文件夹。\n",
    "        extensions (List[str]): 要匹配的文件扩展名列表。\n",
    "        exclude (str, optional): 要排除的通配符模式。默认为 \"^$\", 代表完全不排除。\n",
    "        recursive (bool, optional): 是否递归到子目录。默认为 False。\n",
    "\n",
    "    Yields:\n",
    "        str: 文件路径。\n",
    "    \"\"\"\n",
    "    # 验证输入文件夹\n",
    "    if not os.path.isdir(folder):\n",
    "        raise ValueError(\"'{}' 不是存在的文件夹\".format(folder))\n",
    "    # 使用 os.scandir 遍历文件夹中的条目\n",
    "    with os.scandir(folder) as it:\n",
    "        for entry in it:\n",
    "            # 检查条目是否为文件，并且其名称是否与扩展名和排除模式匹配\n",
    "            if (entry.is_file() \n",
    "                and entry.name.endswith(tuple(extensions)) \n",
    "                and not re.search(exclude, entry.path)):\n",
    "                # 输出文件路径\n",
    "                yield entry.path\n",
    "            # 检查条目是否为目录，并且是否启用递归扫描\n",
    "            elif entry.is_dir() and recursive:\n",
    "                # 递归到子目录\n",
    "                yield from scan_file_path(entry.path, extensions, exclude, recursive)\n",
    "\n",
    "\n",
    "\n",
    "# 示例代码\n",
    "if __name__ == \"__main__\":\n",
    "  extensions = ['.csv','.dta']\n",
    "  folder = \".\" \n",
    "  exclude = r\".csv$\"\n",
    "  paths1 = scan_file_path(folder,extensions,recursive=True)\n",
    "  paths2 = scan_file_path(folder,extensions,recursive=True,exclude=exclude)\n",
    "\n",
    "  for path in paths1:\n",
    "    print(f\"未排除csv文件的路径如下: \\n {path} \\n\")\n",
    "\n",
    "  for path in paths2:\n",
    "    print(f\"排除csv文件的路径如下: \\n {path} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3} \n",
      "\n",
      "     value\n",
      "key       \n",
      "a        1\n",
      "b        2\n",
      "c        3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "def dict_to_df(_dict: Dict[Any, Any], key_name: str, value_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    字典转换为一个dataframe, 字典键对应第一列，字典值第二列。\n",
    "\n",
    "    参数：\n",
    "    _dict (Dict[Any, Any]): 字典。\n",
    "    key_name (str): 字典的keys对应的列名。\n",
    "    value_name (str): 字典的values对应的列名。\n",
    "    \n",
    "    返回值：\n",
    "    df(pd.DataFrame): 一个两列dataframe，第一列对应字典的keys，第二列对应字典的values。\n",
    "    \"\"\"\n",
    "    df = (pd.DataFrame.from_dict(_dict, orient='index', columns=[value_name])\n",
    "        .rename_axis(key_name))\n",
    "  \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 定义测试字典\n",
    "    test_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "\n",
    "    # 调用 dict_to_df 函数\n",
    "    df = dict_to_df(test_dict, 'key', 'value')\n",
    "\n",
    "    # 打印输出结果，查看是否符合预期\n",
    "    print(f\"{test_dict} \\n\")\n",
    "    print(f\"{df} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成器data1中的df块1:\n",
      "      _column_name       _column_label _value_label_name _value_label  wage  \\\n",
      "0            wage   earnings per hour               NaN          NaN  1.05   \n",
      "1            educ  years of education               NaN          NaN  1.05   \n",
      "2             age        age in years               NaN          NaN  1.23   \n",
      "3           exper          experience               NaN          NaN  1.28   \n",
      "4          female        =1 if female               NaN          NaN  1.34   \n",
      "...           ...                 ...               ...          ...   ...   \n",
      "2495          NaN                 NaN               NaN          NaN  8.84   \n",
      "2496          NaN                 NaN               NaN          NaN  8.84   \n",
      "2497          NaN                 NaN               NaN          NaN  8.84   \n",
      "2498          NaN                 NaN               NaN          NaN  8.84   \n",
      "2499          NaN                 NaN               NaN          NaN  8.84   \n",
      "\n",
      "      educ   age  exper  female  black  white  married  union  northeast  \\\n",
      "0     12.0  37.0   19.0     0.0    0.0    1.0      0.0    1.0        0.0   \n",
      "1     13.0  42.0   23.0     0.0    0.0    1.0      0.0    0.0        1.0   \n",
      "2      8.0  54.0   40.0     0.0    0.0    1.0      0.0    0.0        0.0   \n",
      "3     10.0  59.0   43.0     1.0    0.0    1.0      1.0    1.0        1.0   \n",
      "4     18.0  28.0    4.0     1.0    0.0    1.0      0.0    0.0        0.0   \n",
      "...    ...   ...    ...     ...    ...    ...      ...    ...        ...   \n",
      "2495  14.0  43.0   23.0     0.0    0.0    1.0      0.0    0.0        0.0   \n",
      "2496  13.0  24.0    5.0     1.0    0.0    1.0      0.0    0.0        0.0   \n",
      "2497  12.0  57.0   39.0     0.0    1.0    0.0      1.0    0.0        0.0   \n",
      "2498  14.0  24.0    4.0     0.0    1.0    0.0      0.0    0.0        0.0   \n",
      "2499  13.0  21.0    2.0     1.0    0.0    1.0      0.0    0.0        1.0   \n",
      "\n",
      "      midwest  south  west  fulltime  metro  \n",
      "0         0.0    0.0   1.0       1.0    1.0  \n",
      "1         0.0    0.0   0.0       1.0    1.0  \n",
      "2         0.0    0.0   1.0       1.0    1.0  \n",
      "3         0.0    0.0   0.0       0.0    1.0  \n",
      "4         0.0    0.0   1.0       1.0    0.0  \n",
      "...       ...    ...   ...       ...    ...  \n",
      "2495      0.0    0.0   1.0       0.0    0.0  \n",
      "2496      0.0    1.0   0.0       1.0    1.0  \n",
      "2497      1.0    0.0   0.0       1.0    1.0  \n",
      "2498      0.0    1.0   0.0       1.0    1.0  \n",
      "2499      0.0    0.0   0.0       1.0    1.0  \n",
      "\n",
      "[2500 rows x 19 columns]\n",
      "_column_name          object\n",
      "_column_label         object\n",
      "_value_label_name     object\n",
      "_value_label          object\n",
      "wage                 float64\n",
      "educ                 float64\n",
      "age                  float64\n",
      "exper                float64\n",
      "female               float64\n",
      "black                float64\n",
      "white                float64\n",
      "married              float64\n",
      "union                float64\n",
      "northeast            float64\n",
      "midwest              float64\n",
      "south                float64\n",
      "west                 float64\n",
      "fulltime             float64\n",
      "metro                float64\n",
      "dtype: object \n",
      "\n",
      "生成器data1中的df块2:\n",
      "      _column_name       _column_label _value_label_name _value_label  \\\n",
      "0            wage   earnings per hour               NaN          NaN   \n",
      "1            educ  years of education               NaN          NaN   \n",
      "2             age        age in years               NaN          NaN   \n",
      "3           exper          experience               NaN          NaN   \n",
      "4          female        =1 if female               NaN          NaN   \n",
      "...           ...                 ...               ...          ...   \n",
      "4728          NaN                 NaN               NaN          NaN   \n",
      "4729          NaN                 NaN               NaN          NaN   \n",
      "4730          NaN                 NaN               NaN          NaN   \n",
      "4731          NaN                 NaN               NaN          NaN   \n",
      "4732          NaN                 NaN               NaN          NaN   \n",
      "\n",
      "           wage  educ   age  exper  female  black  white  married  union  \\\n",
      "0           NaN   NaN   NaN    NaN     NaN    NaN    NaN      NaN    NaN   \n",
      "1           NaN   NaN   NaN    NaN     NaN    NaN    NaN      NaN    NaN   \n",
      "2           NaN   NaN   NaN    NaN     NaN    NaN    NaN      NaN    NaN   \n",
      "3           NaN   NaN   NaN    NaN     NaN    NaN    NaN      NaN    NaN   \n",
      "4           NaN   NaN   NaN    NaN     NaN    NaN    NaN      NaN    NaN   \n",
      "...         ...   ...   ...    ...     ...    ...    ...      ...    ...   \n",
      "4728  47.220001  18.0  59.0   35.0     0.0    0.0    1.0      1.0    1.0   \n",
      "4729  56.480000   9.0  63.0   48.0     0.0    0.0    1.0      1.0    0.0   \n",
      "4730  60.189999  16.0  55.0   33.0     0.0    0.0    1.0      1.0    1.0   \n",
      "4731  74.320000  18.0  41.0   17.0     0.0    0.0    1.0      1.0    0.0   \n",
      "4732  78.709999  18.0  63.0   39.0     1.0    0.0    1.0      0.0    0.0   \n",
      "\n",
      "      northeast  midwest  south  west  fulltime  metro  \n",
      "0           NaN      NaN    NaN   NaN       NaN    NaN  \n",
      "1           NaN      NaN    NaN   NaN       NaN    NaN  \n",
      "2           NaN      NaN    NaN   NaN       NaN    NaN  \n",
      "3           NaN      NaN    NaN   NaN       NaN    NaN  \n",
      "4           NaN      NaN    NaN   NaN       NaN    NaN  \n",
      "...         ...      ...    ...   ...       ...    ...  \n",
      "4728        1.0      0.0    0.0   0.0       0.0    1.0  \n",
      "4729        0.0      1.0    0.0   0.0       0.0    1.0  \n",
      "4730        0.0      0.0    0.0   1.0       0.0    1.0  \n",
      "4731        1.0      0.0    0.0   0.0       0.0    1.0  \n",
      "4732        0.0      0.0    1.0   0.0       0.0    1.0  \n",
      "\n",
      "[2248 rows x 19 columns]\n",
      "_column_name          object\n",
      "_column_label         object\n",
      "_value_label_name     object\n",
      "_value_label          object\n",
      "wage                 float64\n",
      "educ                 float64\n",
      "age                  float64\n",
      "exper                float64\n",
      "female               float64\n",
      "black                float64\n",
      "white                float64\n",
      "married              float64\n",
      "union                float64\n",
      "northeast            float64\n",
      "midwest              float64\n",
      "south                float64\n",
      "west                 float64\n",
      "fulltime             float64\n",
      "metro                float64\n",
      "dtype: object \n",
      "\n",
      "生成器data2中的df块1:\n",
      "    _column_name                     _column_label _value_label_name  \\\n",
      "0          wage                 earnings per hour               NaN   \n",
      "1          educ                years of education               NaN   \n",
      "2           age                      age in years               NaN   \n",
      "3         exper                        experience               NaN   \n",
      "4        female                      =1 if female               NaN   \n",
      "5         black                       =1 if black               NaN   \n",
      "6         white                       =1 if white               NaN   \n",
      "7       married                     =1 if married               NaN   \n",
      "8         union                =1 if union member               NaN   \n",
      "9     northeast                   =1 if northeast               NaN   \n",
      "10      midwest                     =1 if midwest               NaN   \n",
      "11        south                       =1 if south               NaN   \n",
      "12         west                        =1 if west               NaN   \n",
      "13     fulltime            =1 if full time worker               NaN   \n",
      "14        metro  =1 if lives in metropolitan area               NaN   \n",
      "\n",
      "   _value_label  \n",
      "0           NaN  \n",
      "1           NaN  \n",
      "2           NaN  \n",
      "3           NaN  \n",
      "4           NaN  \n",
      "5           NaN  \n",
      "6           NaN  \n",
      "7           NaN  \n",
      "8           NaN  \n",
      "9           NaN  \n",
      "10          NaN  \n",
      "11          NaN  \n",
      "12          NaN  \n",
      "13          NaN  \n",
      "14          NaN  \n",
      "生成器data3中的df块1:\n",
      "       wage  educ   age  exper  female  black  white  married  union  \\\n",
      "0     1.05  12.0  37.0   19.0     0.0    0.0    1.0      0.0    1.0   \n",
      "1     1.05  13.0  42.0   23.0     0.0    0.0    1.0      0.0    0.0   \n",
      "2     1.23   8.0  54.0   40.0     0.0    0.0    1.0      0.0    0.0   \n",
      "3     1.28  10.0  59.0   43.0     1.0    0.0    1.0      1.0    1.0   \n",
      "4     1.34  18.0  28.0    4.0     1.0    0.0    1.0      0.0    0.0   \n",
      "...    ...   ...   ...    ...     ...    ...    ...      ...    ...   \n",
      "2495  8.84  14.0  43.0   23.0     0.0    0.0    1.0      0.0    0.0   \n",
      "2496  8.84  13.0  24.0    5.0     1.0    0.0    1.0      0.0    0.0   \n",
      "2497  8.84  12.0  57.0   39.0     0.0    1.0    0.0      1.0    0.0   \n",
      "2498  8.84  14.0  24.0    4.0     0.0    1.0    0.0      0.0    0.0   \n",
      "2499  8.84  13.0  21.0    2.0     1.0    0.0    1.0      0.0    0.0   \n",
      "\n",
      "      northeast  midwest  south  west  fulltime  metro  \n",
      "0           0.0      0.0    0.0   1.0       1.0    1.0  \n",
      "1           1.0      0.0    0.0   0.0       1.0    1.0  \n",
      "2           0.0      0.0    0.0   1.0       1.0    1.0  \n",
      "3           1.0      0.0    0.0   0.0       0.0    1.0  \n",
      "4           0.0      0.0    0.0   1.0       1.0    0.0  \n",
      "...         ...      ...    ...   ...       ...    ...  \n",
      "2495        0.0      0.0    0.0   1.0       0.0    0.0  \n",
      "2496        0.0      0.0    1.0   0.0       1.0    1.0  \n",
      "2497        0.0      1.0    0.0   0.0       1.0    1.0  \n",
      "2498        0.0      0.0    1.0   0.0       1.0    1.0  \n",
      "2499        1.0      0.0    0.0   0.0       1.0    1.0  \n",
      "\n",
      "[2500 rows x 15 columns]\n",
      "生成器data3中的df块2:\n",
      "            wage  educ   age  exper  female  black  white  married  union  \\\n",
      "2500   8.840000  16.0  48.0   26.0     1.0    0.0    1.0      0.0    1.0   \n",
      "2501   8.840000  13.0  33.0   14.0     1.0    0.0    1.0      1.0    1.0   \n",
      "2502   8.840000  12.0  40.0   22.0     1.0    0.0    1.0      1.0    0.0   \n",
      "2503   8.840000  12.0  38.0   20.0     0.0    0.0    1.0      1.0    0.0   \n",
      "2504   8.840000  12.0  61.0   43.0     1.0    0.0    1.0      0.0    1.0   \n",
      "...         ...   ...   ...    ...     ...    ...    ...      ...    ...   \n",
      "4728  47.220001  18.0  59.0   35.0     0.0    0.0    1.0      1.0    1.0   \n",
      "4729  56.480000   9.0  63.0   48.0     0.0    0.0    1.0      1.0    0.0   \n",
      "4730  60.189999  16.0  55.0   33.0     0.0    0.0    1.0      1.0    1.0   \n",
      "4731  74.320000  18.0  41.0   17.0     0.0    0.0    1.0      1.0    0.0   \n",
      "4732  78.709999  18.0  63.0   39.0     1.0    0.0    1.0      0.0    0.0   \n",
      "\n",
      "      northeast  midwest  south  west  fulltime  metro  \n",
      "2500        1.0      0.0    0.0   0.0       1.0    1.0  \n",
      "2501        0.0      0.0    0.0   1.0       1.0    1.0  \n",
      "2502        0.0      0.0    1.0   0.0       1.0    1.0  \n",
      "2503        1.0      0.0    0.0   0.0       1.0    1.0  \n",
      "2504        1.0      0.0    0.0   0.0       1.0    0.0  \n",
      "...         ...      ...    ...   ...       ...    ...  \n",
      "4728        1.0      0.0    0.0   0.0       0.0    1.0  \n",
      "4729        0.0      1.0    0.0   0.0       0.0    1.0  \n",
      "4730        0.0      0.0    0.0   1.0       0.0    1.0  \n",
      "4731        1.0      0.0    0.0   0.0       0.0    1.0  \n",
      "4732        0.0      0.0    1.0   0.0       0.0    1.0  \n",
      "\n",
      "[2233 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Generator, List\n",
    "\n",
    "def stata_to_chunks(\n",
    "    file_path: str, \n",
    "    chunksize: int=1000, \n",
    "    keep_data: str = 'all', \n",
    "    convert_categoricals:bool=False,\n",
    "    preserve_dtypes:bool=False,\n",
    "    convert_missing:bool=True,\n",
    "    usecols:List[str]|None=None) -> Generator:\n",
    "    \"\"\"\n",
    "    读取 Stata 文件并返回数据和标签。\n",
    "    \n",
    "    参数:\n",
    "    file_path (str): Stata 文件的路径。\n",
    "    chunksize (int): 读取stata文件的数据块的大小。\n",
    "    keep_data (str): 保留数据的类型, 'all'为数据和标签，'only_label'仅标签，'only_data'仅数据，默认为'all'。\n",
    "    convert_categoricals (bool): 是否转换原始值为值标签对应值，默认值为False。注意，有些文件转换会报错。\n",
    "    convert_missing (bool): 是否以stata缺失值类型存储，默认值为True。\n",
    "    usecols (List[str]|None): 保留的列，默认值None保留所有列。\n",
    "\n",
    "    \n",
    "    返回值:\n",
    "    Generator: 返回一个(DataFrame)生成器。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 创建 StataReader 并设置参数。\n",
    "    reader = pd.read_stata(\n",
    "        file_path, \n",
    "        chunksize=chunksize, \n",
    "        convert_categoricals=convert_categoricals,\n",
    "        preserve_dtypes=preserve_dtypes,\n",
    "        convert_missing=convert_missing,\n",
    "        columns=usecols)\n",
    "    # 如果保留标签信息\n",
    "    if keep_data in ['all','only_label']:\n",
    "        # 获取Stata文件的变量标签dataframe\n",
    "        variable_labels = dict_to_df(\n",
    "            reader.variable_labels(),\n",
    "            key_name='_column_name',\n",
    "            value_name='_column_label').reset_index()\n",
    "        # 获取Stata文件的值标签dataframe\n",
    "        value_labels = dict_to_df(\n",
    "            reader.value_labels(),\n",
    "            key_name='_value_label_name',\n",
    "            value_name='_value_label').reset_index()\n",
    "        # Outer横向合并生成标签dataframe\n",
    "        label = pd.merge(\n",
    "            variable_labels,\n",
    "            value_labels,\n",
    "            left_on='_column_name',\n",
    "            right_on='_value_label_name',\n",
    "            how='outer',\n",
    "            copy=False)\n",
    "\n",
    "        if keep_data == \"only_label\":\n",
    "            # 仅返回label信息\n",
    "            yield label\n",
    "            \n",
    "        else: \n",
    "            # 返回包含标签和数据的信息\n",
    "            for df in reader:\n",
    "                labels = pd.concat([label,df],axis=1,join='outer')\n",
    "                yield labels\n",
    "    elif keep_data == \"only_data\":\n",
    "        # 仅返回数据数据dataframe块\n",
    "        yield from reader\n",
    "    \n",
    "    else:\n",
    "        # 返回错误\n",
    "        raise ValueError(f\"paramter 'keep_data' in function 'stata_to_chunks()' got an unexpected value '{keep_data}'\")\n",
    "\n",
    "\n",
    "# 函数调用示例：\n",
    "if __name__ == \"__main__\":\n",
    "    # 生成两个示例的df chunks生成器\n",
    "    data1 = stata_to_chunks(\"http://www.principlesofeconometrics.com/stata/cps.dta\",chunksize=2500)\n",
    "    data2 = stata_to_chunks(\"http://www.principlesofeconometrics.com/stata/cps.dta\",chunksize=2500,keep_data=\"only_label\")\n",
    "    data3 = stata_to_chunks(\"http://www.principlesofeconometrics.com/stata/cps.dta\",chunksize=2500,keep_data=\"only_data\")\n",
    "   \n",
    "    # # 遍历生成器\n",
    "    for index, df in enumerate(data1):\n",
    "        print(f\"生成器data1中的df块{index+1}:\\n {df}\")\n",
    "        print(df.dtypes, \"\\n\")\n",
    "    for index, df in enumerate(data2):\n",
    "        print(f\"生成器data2中的df块{index+1}:\\n {df}\")\n",
    "    for index, df in enumerate(data3):\n",
    "        print(f\"生成器data3中的df块{index+1}:\\n {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['table1_1', 'table2_1', 'table3_1', 'table1', 'table2', 'table3']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def get_table_names(db_file: str) -> List[str]:\n",
    "    \"\"\"获取给定数据库中的表名列表。\n",
    "\n",
    "    Args:\n",
    "        db_file: 数据库文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        数据库中的表名列表。\n",
    "    \"\"\"\n",
    "    # 获取数据库中的所有表名\n",
    "    with sqlite3.connect(db_file) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        table_names = [table[0] for table in cursor]\n",
    "\n",
    "    # 如果给定的表名在列表中，则返回 True，否则返回 False\n",
    "    return table_names\n",
    "\n",
    "# 示例调用\n",
    "print(get_table_names('my_database.db'))  # 输出：True 或 False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def get_unique_name(name: str, name_list: List[str]) -> str:\n",
    "    \"\"\"获取唯一的名字。\n",
    "\n",
    "    如果给定的名字已经在列表中，则提示用户输入新的名字，直到输入的名字在列表中不存在为止。返回不存在于列表中的名字。\n",
    "\n",
    "    参数:\n",
    "    name: str 需要检查的名字。\n",
    "    name_list: List[str] 名字列表。\n",
    "\n",
    "    返回:\n",
    "    str: 不存在于列表中的名字。\n",
    "    \"\"\"\n",
    "    new_name = name\n",
    "    while new_name in name_list:\n",
    "        new_name = input(\"请输入一个新的名字: \")\n",
    "    return new_name\n",
    "\n",
    "def delete_table(table_name: str, db_file: str):\n",
    "    \"\"\"\n",
    "    在指定数据库文件中删除指定的表。\n",
    "\n",
    "    参数:\n",
    "    - table_name: 需要删除的表的名称。\n",
    "    - db_file: 数据库文件的路径。\n",
    "    \"\"\"\n",
    "    with sqlite3.connect(db_file) as conn:\n",
    "        c = conn.cursor()\n",
    "        c.execute(f\"DROP TABLE {table_name}\")\n",
    "\n",
    "def name_table(name: str, db_file: str, delete_existing_table: bool = False) -> str | None:\n",
    "    \"\"\"\n",
    "    为 SQLite 数据库表命名。如与原表名冲突，则选择要么重命名要么删除原表。\n",
    "\n",
    "    参数：\n",
    "    - name (str): 用户定义的名称。\n",
    "    - db_file (str): SQLite 数据库的文件路径。\n",
    "    - delete_existing_table (bool): 当表存在时，False（默认）为用户输入新名，True 为删除原表。\n",
    "\n",
    "    返回值：\n",
    "    - str | None: 表名或 None。\n",
    "    \"\"\"\n",
    "    # 获取 SQLite 数据库中的全部表名\n",
    "    table_names = get_table_names(db_file)\n",
    "    \n",
    "    # 当命名与已有表名冲突时\n",
    "    if name in table_names:\n",
    "        # 删除原表或输入新名字\n",
    "        return delete_table(name, db_file) if delete_existing_table else get_unique_name(name, table_names)\n",
    "    else:\n",
    "        # 返回原名\n",
    "        return name\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 函数调用示例：\n",
    "if __name__ == \"__main__\":\n",
    "    table_name = name_table('table1',\"my_database.db\",delete_existing_table=True)\n",
    "    print(table_name,'\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
